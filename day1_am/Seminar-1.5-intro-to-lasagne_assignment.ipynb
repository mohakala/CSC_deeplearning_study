{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# lasagne\n",
    "* lasagne is a library for neural network building and training\n",
    "* it's a low-level library with almost seamless integration with theano\n",
    "\n",
    "For a demo we shall solve the same digit recognition problem, but at a different scale\n",
    "* images are now 28x28\n",
    "* 10 different digits\n",
    "* 50k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu0,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu0,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "from mnist import load_dataset\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_dataset()\n",
    "\n",
    "print (X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aaf2c18>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa7aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5**4,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_X = T.tensor4(\"X\")\n",
    "\n",
    "#input dimention (None means \"Arbitrary\" and only works at  the first axes [samples])\n",
    "input_shape = [None,1,28,28]\n",
    "\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "#Input layer (auxilary)\n",
    "l1 = InputLayer(shape = input_shape,input_var=input_X)\n",
    "\n",
    "#fully connected layer, that takes input layer and applies 50 neurons to it.\n",
    "# nonlinearity here is sigmoid as in logistic regression\n",
    "# you can give a name to each layer (optional)\n",
    "l2 = Conv2DLayer(l1,32,(3,3),nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "\n",
    "l3 = Pool2DLayer(l2,(2,2))\n",
    "\n",
    "#Batch normalization, Before sigma, is more effective --> Recommended\n",
    "#l3=batch_norm(l3) # Better then to use nonlinearities.elu ... \n",
    "\n",
    "\n",
    "l4 = DenseLayer(l3,512,nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "l4 = DropoutLayer(l4,0.5)\n",
    "\n",
    "#fully connected output layer that takes dense_1 as input and has 10 neurons (1 for each digit)\n",
    "#We use softmax nonlinearity to make probabilities add up to 1\n",
    "l_out = DenseLayer(l4,num_units = 10,nonlinearity=lasagne.nonlinearities.softmax,name=\"out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#network prediction (theano-transformation)\n",
    "y_predicted = lasagne.layers.get_output(l_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, out.W, out.b]\n"
     ]
    }
   ],
   "source": [
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(l_out) # add trainable=True ... ?\n",
    "print (all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Than you could simply\n",
    "* define loss function manually\n",
    "* compute error gradient over all weights\n",
    "* define updates\n",
    "* But that's a whole lot of work and life's short\n",
    "  * not to mention life's too short to wait for SGD to converge\n",
    "\n",
    "Instead, we shall use Lasagne builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted,target_y).mean()\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted,target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adadelta(loss, all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#network prediction (theano-transformation)\n",
    "y_predicted_det = lasagne.layers.get_output(l_out,deterministic=True)\n",
    "\n",
    "accuracy_det = lasagne.objectives.categorical_accuracy(y_predicted_det,target_y).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X,target_y],[loss,accuracy],updates= updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### That's all, now let's train it!\n",
    "* We got a lot of data, so it's recommended that you use SGD\n",
    "* So let's implement a function that splits the training sample into minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# An auxilary function that returns mini-batches for neural network training\n",
    "\n",
    "#Parameters\n",
    "# inputs - a tensor of images with shape (many, 1, 28, 28), e.g. X_train\n",
    "# outputs - a vector of answers for corresponding images e.g. Y_train\n",
    "#batch_size - a single number - the intended size of each batches\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize):\n",
    "    assert len(inputs) == len(targets)\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-68f96a968304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mhaa\\Anaconda3\\envs\\deep\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mhaa\\Anaconda3\\envs\\deep\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 10 #amount of passes through the data\n",
    "\n",
    "batch_size = 50 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t10.10 %\n",
      "We need more magic!\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 99:\n",
    "    print (\"Achievement unlocked: 80lvl Warlock!\")\n",
    "else:\n",
    "    print (\"We need more magic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Now improve it!\n",
    "\n",
    "* Moar layers!\n",
    "* Moar units!\n",
    "* Different nonlinearities!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
